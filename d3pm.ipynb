{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48536bd6-f64a-4679-b4d0-2e446bd25226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fceb0f5-fe2a-4b92-9b82-fce44c8c51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk = lambda ic, oc: nn.Sequential(\n",
    "    nn.Conv2d(ic, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(oc, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(oc, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    ")\n",
    "\n",
    "blku = lambda ic, oc: nn.Sequential(\n",
    "    nn.Conv2d(ic, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(oc, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(oc, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.ConvTranspose2d(oc, oc, 2, stride=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    ")\n",
    "\n",
    "\n",
    "class DummyX0Model(nn.Module):\n",
    "\n",
    "    def __init__(self, n_channel: int, N: int = 16) -> None:\n",
    "        super(DummyX0Model, self).__init__()\n",
    "        self.down1 = blk(n_channel, 16)\n",
    "        self.down2 = blk(16, 32)\n",
    "        self.down3 = blk(32, 64)\n",
    "        self.down4 = blk(64, 512)\n",
    "        self.down5 = blk(512, 512)\n",
    "        self.up1 = blku(512, 512)\n",
    "        self.up2 = blku(512 + 512, 64)\n",
    "        self.up3 = blku(64, 32)\n",
    "        self.up4 = blku(32, 16)\n",
    "        self.convlast = blk(16, 16)\n",
    "        self.final = nn.Conv2d(16, N * n_channel, 1, bias=False)\n",
    "\n",
    "        self.tr1 = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.tr2 = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.tr3 = nn.TransformerEncoderLayer(d_model=64, nhead=8)\n",
    "\n",
    "        self.cond_embedding_1 = nn.Embedding(10, 16)\n",
    "        self.cond_embedding_2 = nn.Embedding(10, 32)\n",
    "        self.cond_embedding_3 = nn.Embedding(10, 64)\n",
    "        self.cond_embedding_4 = nn.Embedding(10, 512)\n",
    "        self.cond_embedding_5 = nn.Embedding(10, 512)\n",
    "        self.cond_embedding_6 = nn.Embedding(10, 64)\n",
    "\n",
    "        self.temb_1 = nn.Linear(32, 16)\n",
    "        self.temb_2 = nn.Linear(32, 32)\n",
    "        self.temb_3 = nn.Linear(32, 64)\n",
    "        self.temb_4 = nn.Linear(32, 512)\n",
    "        self.N = N\n",
    "\n",
    "    def forward(self, x, t, cond) -> torch.Tensor:\n",
    "        x = (2 * x.float() / self.N) - 1.0\n",
    "        t = t.float().reshape(-1, 1) / 1000\n",
    "        t_features = [torch.sin(t * 3.1415 * 2**i) for i in range(16)] + [\n",
    "            torch.cos(t * 3.1415 * 2**i) for i in range(16)\n",
    "        ]\n",
    "        tx = torch.cat(t_features, dim=1).to(x.device)\n",
    "\n",
    "        t_emb_1 = self.temb_1(tx).unsqueeze(-1).unsqueeze(-1)\n",
    "        t_emb_2 = self.temb_2(tx).unsqueeze(-1).unsqueeze(-1)\n",
    "        t_emb_3 = self.temb_3(tx).unsqueeze(-1).unsqueeze(-1)\n",
    "        t_emb_4 = self.temb_4(tx).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        cond_emb_1 = self.cond_embedding_1(cond).unsqueeze(-1).unsqueeze(-1)\n",
    "        cond_emb_2 = self.cond_embedding_2(cond).unsqueeze(-1).unsqueeze(-1)\n",
    "        cond_emb_3 = self.cond_embedding_3(cond).unsqueeze(-1).unsqueeze(-1)\n",
    "        cond_emb_4 = self.cond_embedding_4(cond).unsqueeze(-1).unsqueeze(-1)\n",
    "        cond_emb_5 = self.cond_embedding_5(cond).unsqueeze(-1).unsqueeze(-1)\n",
    "        cond_emb_6 = self.cond_embedding_6(cond).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        x1 = self.down1(x) + t_emb_1 + cond_emb_1\n",
    "        x2 = self.down2(nn.functional.avg_pool2d(x1, 2)) + t_emb_2 + cond_emb_2\n",
    "        x3 = self.down3(nn.functional.avg_pool2d(x2, 2)) + t_emb_3 + cond_emb_3\n",
    "        x4 = self.down4(nn.functional.avg_pool2d(x3, 2)) + t_emb_4 + cond_emb_4\n",
    "        x5 = self.down5(nn.functional.avg_pool2d(x4, 2))\n",
    "\n",
    "        x5 = (\n",
    "            self.tr1(x5.reshape(x5.shape[0], x5.shape[1], -1).transpose(1, 2))\n",
    "            .transpose(1, 2)\n",
    "            .reshape(x5.shape)\n",
    "        )\n",
    "\n",
    "        y = self.up1(x5) + cond_emb_5\n",
    "\n",
    "        y = (\n",
    "            self.tr2(y.reshape(y.shape[0], y.shape[1], -1).transpose(1, 2))\n",
    "            .transpose(1, 2)\n",
    "            .reshape(y.shape)\n",
    "        )\n",
    "\n",
    "        y = self.up2(torch.cat([x4, y], dim=1)) + cond_emb_6\n",
    "\n",
    "        y = (\n",
    "            self.tr3(y.reshape(y.shape[0], y.shape[1], -1).transpose(1, 2))\n",
    "            .transpose(1, 2)\n",
    "            .reshape(y.shape)\n",
    "        )\n",
    "        y = self.up3(y)\n",
    "        y = self.up4(y)\n",
    "        y = self.convlast(y)\n",
    "        y = self.final(y)\n",
    "\n",
    "        # reshape to B, C, H, W, N\n",
    "        y = (\n",
    "            y.reshape(y.shape[0], -1, self.N, *x.shape[2:])\n",
    "            .transpose(2, -1)\n",
    "            .contiguous()\n",
    "        )\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class D3PM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x0_model: nn.Module,\n",
    "        n_T: int,\n",
    "        num_classes: int = 10,\n",
    "        forward_type=\"uniform\",\n",
    "        hybrid_loss_coeff=0.001,\n",
    "    ) -> None:\n",
    "        super(D3PM, self).__init__()\n",
    "        self.x0_model = x0_model\n",
    "\n",
    "        self.n_T = n_T\n",
    "        self.hybrid_loss_coeff = hybrid_loss_coeff\n",
    "\n",
    "        steps = torch.arange(n_T + 1, dtype=torch.float64) / n_T\n",
    "        alpha_bar = torch.cos((steps + 0.008) / 1.008 * torch.pi / 2)\n",
    "        self.beta_t = torch.minimum(\n",
    "            1 - alpha_bar[1:] / alpha_bar[:-1], torch.ones_like(alpha_bar[1:]) * 0.999\n",
    "        )\n",
    "\n",
    "        # self.beta_t = [1 / (self.n_T - t + 1) for t in range(1, self.n_T + 1)]\n",
    "        self.eps = 1e-6\n",
    "        self.num_classses = num_classes\n",
    "        q_onestep_mats = []\n",
    "        q_mats = []  # these are cumulative\n",
    "\n",
    "        for beta in self.beta_t:\n",
    "\n",
    "            if forward_type == \"uniform\":\n",
    "                mat = torch.ones(num_classes, num_classes) * beta / num_classes\n",
    "                mat.diagonal().fill_(1 - (num_classes - 1) * beta / num_classes)\n",
    "                q_onestep_mats.append(mat)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        q_one_step_mats = torch.stack(q_onestep_mats, dim=0)\n",
    "\n",
    "        q_one_step_transposed = q_one_step_mats.transpose(\n",
    "            1, 2\n",
    "        )  # this will be used for q_posterior_logits\n",
    "\n",
    "        q_mat_t = q_onestep_mats[0]\n",
    "        q_mats = [q_mat_t]\n",
    "        for idx in range(1, self.n_T):\n",
    "            q_mat_t = q_mat_t @ q_onestep_mats[idx]\n",
    "            q_mats.append(q_mat_t)\n",
    "        q_mats = torch.stack(q_mats, dim=0)\n",
    "        self.logit_type = \"logit\"\n",
    "\n",
    "        # register\n",
    "        self.register_buffer(\"q_one_step_transposed\", q_one_step_transposed)\n",
    "        self.register_buffer(\"q_mats\", q_mats)\n",
    "\n",
    "        assert self.q_mats.shape == (\n",
    "            self.n_T,\n",
    "            num_classes,\n",
    "            num_classes,\n",
    "        ), self.q_mats.shape\n",
    "\n",
    "    def _at(self, a, t, x):\n",
    "        # t is 1-d, x is integer value of 0 to num_classes - 1\n",
    "        bs = t.shape[0]\n",
    "        t = t.reshape((bs, *[1] * (x.dim() - 1)))\n",
    "        # out[i, j, k, l, m] = a[t[i, j, k, l], x[i, j, k, l], m]\n",
    "        return a[t - 1, x, :]\n",
    "\n",
    "    def q_posterior_logits(self, x_0, x_t, t):\n",
    "        # if t == 1, this means we return the L_0 loss, so directly try to x_0 logits.\n",
    "        # otherwise, we return the L_{t-1} loss.\n",
    "        # Also, we never have t == 0.\n",
    "\n",
    "        # if x_0 is integer, we convert it to one-hot.\n",
    "        if x_0.dtype == torch.int64 or x_0.dtype == torch.int32:\n",
    "            x_0_logits = torch.log(\n",
    "                torch.nn.functional.one_hot(x_0, self.num_classses) + self.eps\n",
    "            )\n",
    "        else:\n",
    "            x_0_logits = x_0.clone()\n",
    "\n",
    "        assert x_0_logits.shape == x_t.shape + (self.num_classses,), print(\n",
    "            f\"x_0_logits.shape: {x_0_logits.shape}, x_t.shape: {x_t.shape}\"\n",
    "        )\n",
    "\n",
    "        # Here, we caclulate equation (3) of the paper. Note that the x_0 Q_t x_t^T is a normalizing constant, so we don't deal with that.\n",
    "\n",
    "        # fact1 is \"guess of x_{t-1}\" from x_t\n",
    "        # fact2 is \"guess of x_{t-1}\" from x_0\n",
    "\n",
    "        fact1 = self._at(self.q_one_step_transposed, t, x_t)\n",
    "\n",
    "        softmaxed = torch.softmax(x_0_logits, dim=-1)  # bs, ..., num_classes\n",
    "        qmats2 = self.q_mats[t - 2].to(dtype=softmaxed.dtype)\n",
    "        # bs, num_classes, num_classes\n",
    "        fact2 = torch.einsum(\"b...c,bcd->b...d\", softmaxed, qmats2)\n",
    "\n",
    "        out = torch.log(fact1 + self.eps) + torch.log(fact2 + self.eps)\n",
    "\n",
    "        t_broadcast = t.reshape((t.shape[0], *[1] * (x_t.dim())))\n",
    "\n",
    "        bc = torch.where(t_broadcast == 1, x_0_logits, out)\n",
    "\n",
    "        return bc\n",
    "\n",
    "    def vb(self, dist1, dist2):\n",
    "\n",
    "        # flatten dist1 and dist2\n",
    "        dist1 = dist1.flatten(start_dim=0, end_dim=-2)\n",
    "        dist2 = dist2.flatten(start_dim=0, end_dim=-2)\n",
    "\n",
    "        out = torch.softmax(dist1 + self.eps, dim=-1) * (\n",
    "            torch.log_softmax(dist1 + self.eps, dim=-1)\n",
    "            - torch.log_softmax(dist2 + self.eps, dim=-1)\n",
    "        )\n",
    "        return out.sum(dim=-1).mean()\n",
    "\n",
    "    def q_sample(self, x_0, t, noise):\n",
    "        # forward process, x_0 is the clean input.\n",
    "        logits = torch.log(self._at(self.q_mats, t, x_0) + self.eps)\n",
    "        noise = torch.clip(noise, self.eps, 1.0)\n",
    "        gumbel_noise = -torch.log(-torch.log(noise))\n",
    "        return torch.argmax(logits + gumbel_noise, dim=-1)\n",
    "\n",
    "    def model_predict(self, x_0, t, cond):\n",
    "        # this part exists because in general, manipulation of logits from model's logit\n",
    "        # so they are in form of x_0's logit might be independent to model choice.\n",
    "        # for example, you can convert 2 * N channel output of model output to logit via get_logits_from_logistic_pars\n",
    "        # they introduce at appendix A.8.\n",
    "\n",
    "        predicted_x0_logits = self.x0_model(x_0, t, cond)\n",
    "\n",
    "        return predicted_x0_logits\n",
    "\n",
    "    def forward(self, x: torch.Tensor, cond: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Makes forward diffusion x_t from x_0, and tries to guess x_0 value from x_t using x0_model.\n",
    "        x is one-hot of dim (bs, ...), with int values of 0 to num_classes - 1\n",
    "        \"\"\"\n",
    "        t = torch.randint(1, self.n_T, (x.shape[0],), device=x.device)\n",
    "        x_t = self.q_sample(\n",
    "            x, t, torch.rand((*x.shape, self.num_classses), device=x.device)\n",
    "        )\n",
    "        # x_t is same shape as x\n",
    "        assert x_t.shape == x.shape, print(\n",
    "            f\"x_t.shape: {x_t.shape}, x.shape: {x.shape}\"\n",
    "        )\n",
    "        # we use hybrid loss.\n",
    "\n",
    "        predicted_x0_logits = self.model_predict(x_t, t, cond)\n",
    "\n",
    "        # based on this, we first do vb loss.\n",
    "        true_q_posterior_logits = self.q_posterior_logits(x, x_t, t)\n",
    "        pred_q_posterior_logits = self.q_posterior_logits(predicted_x0_logits, x_t, t)\n",
    "\n",
    "        vb_loss = self.vb(true_q_posterior_logits, pred_q_posterior_logits)\n",
    "\n",
    "        predicted_x0_logits = predicted_x0_logits.flatten(start_dim=0, end_dim=-2)\n",
    "        x = x.flatten(start_dim=0, end_dim=-1)\n",
    "\n",
    "        ce_loss = torch.nn.CrossEntropyLoss()(predicted_x0_logits, x)\n",
    "\n",
    "        return vb_loss * self.hybrid_loss_coeff + ce_loss, {\n",
    "            \"vb_loss\": vb_loss.detach().item(),\n",
    "            \"ce_loss\": ce_loss.detach().item(),\n",
    "        }\n",
    "\n",
    "    def p_sample(self, x, t, cond, noise):\n",
    "\n",
    "        predicted_x0_logits = self.model_predict(x, t, cond)\n",
    "        pred_q_posterior_logits = self.q_posterior_logits(predicted_x0_logits, x, t)\n",
    "\n",
    "        noise = torch.clip(noise, self.eps, 1.0)\n",
    "\n",
    "        not_first_step = (t != 1).float().reshape((x.shape[0], *[1] * (x.dim())))\n",
    "\n",
    "        gumbel_noise = -torch.log(-torch.log(noise))\n",
    "        sample = torch.argmax(\n",
    "            pred_q_posterior_logits + gumbel_noise * not_first_step, dim=-1\n",
    "        )\n",
    "        return sample\n",
    "\n",
    "    def sample(self, x, cond=None):\n",
    "        for t in reversed(range(1, self.n_T)):\n",
    "            t = torch.tensor([t] * x.shape[0], device=x.device)\n",
    "            x = self.p_sample(\n",
    "                x, t, cond, torch.rand((*x.shape, self.num_classses), device=x.device)\n",
    "            )\n",
    "\n",
    "        return x\n",
    "\n",
    "    def sample_with_image_sequence(self, x, cond=None, stride=10):\n",
    "        steps = 0\n",
    "        images = []\n",
    "        for t in reversed(range(1, self.n_T)):\n",
    "            t = torch.tensor([t] * x.shape[0], device=x.device)\n",
    "            x = self.p_sample(\n",
    "                x, t, cond, torch.rand((*x.shape, self.num_classses), device=x.device)\n",
    "            )\n",
    "            steps += 1\n",
    "            if steps % stride == 0:\n",
    "                images.append(x)\n",
    "\n",
    "        # if last step is not divisible by stride, we add the last image.\n",
    "        if steps % stride != 0:\n",
    "            images.append(x)\n",
    "\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3018ce74-5a2a-45b8-9e51-7537ed3b3331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class IsingDataset(Dataset):\n",
    "    def __init__(self, npz_file, transform=None):\n",
    "        data = np.load(npz_file)\n",
    "        \n",
    "        self.images = (data['data']+1)/2\n",
    "        \n",
    "        mapping = {\n",
    "            np.float64(0.0): 0,\n",
    "            np.float64(0.2): 1,\n",
    "            np.float64(0.4): 2,\n",
    "            np.float64(0.6000000000000001): 3,\n",
    "            np.float64(0.8): 4,\n",
    "            np.float64(1.0): 5,\n",
    "            np.float64(1.2000000000000002): 6,\n",
    "            np.float64(1.4000000000000001): 7,\n",
    "            np.float64(1.6): 8,\n",
    "            np.float64(1.8): 9\n",
    "        }\n",
    "        \n",
    "        # Convert float labels to integer labels using the mapping\n",
    "        self.labels = np.vectorize(mapping.get)(data['labels'])\n",
    "        self.transform = transform\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].astype(np.float32)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.from_numpy(image).unsqueeze(0)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# DataLoader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Pad(2),\n",
    "    # Add other transformations if necessary\n",
    "])\n",
    "\n",
    "dataset = IsingDataset('ising_dataset_2.npz', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd321350-a0be-4183-aaa0-2c937c5c7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d06c76-050c-44d1-aa7c-f6d36cee0d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Param Count: 63278080\n"
     ]
    }
   ],
   "source": [
    "N = 2  # number of classes for discretized state per pixel\n",
    "d3pm = D3PM(DummyX0Model(1, N), 1000, num_classes=N, hybrid_loss_coeff=0.0).to(device)\n",
    "print(f\"Total Param Count: {sum([p.numel() for p in d3pm.x0_model.parameters()])}\")\n",
    "\n",
    "optim = torch.optim.AdamW(d3pm.x0_model.parameters(), lr=1e-3)\n",
    "d3pm.train()\n",
    "\n",
    "n_epoch = 1500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "527559f0-e15c-4516-90d6-6a37dcf80807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset = MNIST(\n",
    "#     \"./data\",\n",
    "#     train=True,\n",
    "#     download=True,\n",
    "#     transform=transforms.Compose(\n",
    "#         [\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Pad(2),\n",
    "#         ]\n",
    "#     ),\n",
    "# )\n",
    "# dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "addba71c-598e-4d11-a632-0465859bb269",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, l in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63422bae-2d2c-4720-8c42-841e84fd79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a599162-b8cc-4a9f-9284-4032423e9b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 7, 6, 4, 9, 6, 7, 3, 6, 0, 8, 9, 1, 0, 6, 0, 3, 8, 6, 4, 6, 7, 9, 7,\n",
       "        2, 0, 3, 4, 9, 2, 0, 8, 5, 2, 4, 4, 9, 2, 8, 5, 6, 5, 7, 3, 3, 1, 7, 2,\n",
       "        0, 1, 2, 4, 1, 0, 1, 7, 5, 6, 3, 8, 3, 8, 4, 3, 9, 4, 7, 8, 4, 4, 9, 9,\n",
       "        0, 1, 7, 3, 2, 4, 9, 7, 8, 9, 0, 3, 0, 5, 2, 6, 2, 9, 6, 6, 7, 9, 9, 8,\n",
       "        1, 7, 4, 3, 4, 0, 5, 2, 5, 8, 0, 3, 2, 6, 7, 7, 6, 0, 2, 8, 2, 5, 6, 3,\n",
       "        4, 3, 1, 8, 3, 4, 7, 8, 4, 3, 7, 3, 8, 7, 3, 4, 9, 5, 2, 2, 8, 0, 4, 4,\n",
       "        9, 2, 4, 9, 0, 0, 9, 9, 0, 5, 0, 1, 8, 2, 9, 9, 4, 5, 9, 5, 1, 7, 6, 0,\n",
       "        1, 5, 4, 5, 6, 0, 0, 5, 1, 4, 5, 6, 8, 5, 9, 7, 6, 4, 5, 8, 6, 8, 0, 5,\n",
       "        3, 2, 5, 5, 2, 8, 1, 3, 2, 0, 5, 9, 0, 9, 3, 5, 6, 7, 9, 6, 0, 2, 4, 7,\n",
       "        5, 5, 5, 7, 8, 8, 7, 3, 8, 7, 9, 6, 2, 8, 0, 1, 6, 0, 4, 8, 1, 4, 6, 2,\n",
       "        6, 4, 5, 6, 8, 8, 7, 5, 3, 4, 6, 0, 3, 4, 4, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf808c1e-e471-46bc-bc35-bf7c24822cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.),\n",
       " tensor(1.),\n",
       " <matplotlib.image.AxesImage at 0x14c3dbcbd5d0>,\n",
       " tensor(9),\n",
       " tensor(0),\n",
       " tensor(7))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k[7].min(), k[10].max(), plt.imshow(k[1][0]), l.max(), l.min(), l[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4429e76-5c73-4bc0-ad08-966cfb89c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ =  'contents_ising'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f81bb7d-8680-4f05-80ae-aaeabf5030c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.5491, norm: 0.0022, param_norm: 1191.2866, vb_loss: 0.0060, ce_loss: 0.5308: 100%|██████████| 235/235 [00:24<00:00,  9.76it/s]\n",
      "loss: 0.5307, norm: 0.0013, param_norm: 1188.7089, vb_loss: 0.0006, ce_loss: 0.5308: 100%|██████████| 235/235 [00:19<00:00, 11.83it/s]\n",
      "loss: 0.5307, norm: 0.0036, param_norm: 1186.0629, vb_loss: 0.0005, ce_loss: 0.5308: 100%|██████████| 235/235 [00:20<00:00, 11.75it/s]\n",
      "loss: 0.5307, norm: 0.0011, param_norm: 1183.5411, vb_loss: 0.0005, ce_loss: 0.5308: 100%|██████████| 235/235 [00:19<00:00, 11.83it/s]\n",
      "loss: 0.5307, norm: 0.0004, param_norm: 1180.8964, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:13<00:00, 17.42it/s]\n",
      "loss: 0.5307, norm: 0.0011, param_norm: 1178.2238, vb_loss: 0.0006, ce_loss: 0.5306: 100%|██████████| 235/235 [00:19<00:00, 11.78it/s]\n",
      "loss: 0.5307, norm: 0.0010, param_norm: 1175.6030, vb_loss: 0.0005, ce_loss: 0.5308: 100%|██████████| 235/235 [00:19<00:00, 11.81it/s]\n",
      "loss: 0.5307, norm: 0.0004, param_norm: 1172.9336, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.87it/s]\n",
      "loss: 0.5307, norm: 0.0008, param_norm: 1170.3030, vb_loss: 0.0061, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.83it/s]\n",
      "loss: 0.5307, norm: 0.0011, param_norm: 1167.8617, vb_loss: 0.0005, ce_loss: 0.5308: 100%|██████████| 235/235 [00:13<00:00, 17.35it/s]\n",
      "loss: 0.5307, norm: 0.0008, param_norm: 1165.2397, vb_loss: 0.0005, ce_loss: 0.5306: 100%|██████████| 235/235 [00:20<00:00, 11.74it/s]\n",
      "loss: 0.5307, norm: 0.0003, param_norm: 1162.6263, vb_loss: 0.0006, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.80it/s]\n",
      "loss: 0.5307, norm: 0.0003, param_norm: 1159.9653, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.81it/s]\n",
      "loss: 0.5307, norm: 0.0012, param_norm: 1157.3079, vb_loss: 0.0006, ce_loss: 0.5306: 100%|██████████| 235/235 [00:13<00:00, 17.40it/s]\n",
      "loss: 0.5307, norm: 0.0004, param_norm: 1154.7767, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.82it/s]\n",
      "loss: 0.5307, norm: 0.0005, param_norm: 1152.1204, vb_loss: 0.0005, ce_loss: 0.5306: 100%|██████████| 235/235 [00:19<00:00, 11.81it/s]\n",
      "loss: 0.5307, norm: 0.0005, param_norm: 1149.4729, vb_loss: 0.0005, ce_loss: 0.5306: 100%|██████████| 235/235 [00:19<00:00, 11.87it/s]\n",
      "loss: 0.5307, norm: 0.0011, param_norm: 1149.3446, vb_loss: 0.0005, ce_loss: 0.5306: 100%|██████████| 235/235 [00:19<00:00, 11.89it/s]\n",
      "loss: 0.5307, norm: 0.0001, param_norm: 1146.7588, vb_loss: 0.0060, ce_loss: 0.5307: 100%|██████████| 235/235 [00:13<00:00, 16.99it/s]\n",
      "loss: 0.5307, norm: 0.0013, param_norm: 1144.2100, vb_loss: 0.0005, ce_loss: 0.5308: 100%|██████████| 235/235 [00:19<00:00, 11.84it/s]\n",
      "loss: 0.5307, norm: 0.0006, param_norm: 1141.5900, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.78it/s]\n",
      "loss: 0.5307, norm: 0.0001, param_norm: 1138.9358, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.82it/s]\n",
      "loss: 0.5307, norm: 0.0003, param_norm: 1136.3263, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.84it/s]\n",
      "loss: 0.5307, norm: 0.0006, param_norm: 1133.7050, vb_loss: 0.0006, ce_loss: 0.5306: 100%|██████████| 235/235 [00:13<00:00, 17.36it/s]\n",
      "loss: 0.5307, norm: 0.0004, param_norm: 1131.1487, vb_loss: 0.0060, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.81it/s]\n",
      "loss: 0.5307, norm: 0.0002, param_norm: 1131.6960, vb_loss: 0.0006, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.82it/s]\n",
      "loss: 0.5307, norm: 0.0002, param_norm: 1129.9539, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.83it/s]\n",
      "loss: 0.5307, norm: 0.0004, param_norm: 1127.3926, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:13<00:00, 17.37it/s]\n",
      "loss: 0.5307, norm: 0.0009, param_norm: 1124.7817, vb_loss: 0.0005, ce_loss: 0.5306: 100%|██████████| 235/235 [00:19<00:00, 11.78it/s]\n",
      "loss: 0.5307, norm: 0.0003, param_norm: 1122.1804, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.77it/s]\n",
      "loss: 0.5307, norm: 0.0003, param_norm: 1119.5881, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.84it/s]\n",
      "loss: 0.5307, norm: 0.0003, param_norm: 1117.0260, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.87it/s]\n",
      "loss: 0.5307, norm: 0.0011, param_norm: 1114.4519, vb_loss: 0.0006, ce_loss: 0.5308: 100%|██████████| 235/235 [00:13<00:00, 17.34it/s]\n",
      "loss: 0.5307, norm: 0.0006, param_norm: 1115.5592, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.75it/s]\n",
      "loss: 0.5307, norm: 0.0014, param_norm: 1113.0309, vb_loss: 0.0006, ce_loss: 0.5308: 100%|██████████| 235/235 [00:19<00:00, 11.82it/s]\n",
      "loss: 0.5307, norm: 0.0002, param_norm: 1110.5314, vb_loss: 0.0060, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.87it/s]\n",
      "loss: 0.5307, norm: 0.0002, param_norm: 1107.9702, vb_loss: 0.0006, ce_loss: 0.5307: 100%|██████████| 235/235 [00:13<00:00, 17.35it/s]\n",
      "loss: 0.5307, norm: 0.0005, param_norm: 1105.4355, vb_loss: 0.0005, ce_loss: 0.5306: 100%|██████████| 235/235 [00:19<00:00, 11.77it/s]\n",
      "loss: 0.5307, norm: 0.0003, param_norm: 1102.9194, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.82it/s]\n",
      "loss: 0.5307, norm: 0.0002, param_norm: 1100.4630, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:20<00:00, 11.46it/s]\n",
      "loss: 0.5307, norm: 0.0001, param_norm: 1097.9486, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:19<00:00, 11.81it/s]\n",
      "loss: 0.5307, norm: 0.0002, param_norm: 1095.4767, vb_loss: 0.0005, ce_loss: 0.5307: 100%|██████████| 235/235 [00:13<00:00, 17.31it/s]\n",
      "loss: 0.5307, norm: 0.0001, param_norm: 1080.2069, vb_loss: 0.0005, ce_loss: 0.5307:  22%|██▏       | 51/235 [00:03<00:10, 17.67it/s]"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "for i in range(n_epoch):\n",
    "\n",
    "    pbar = tqdm(dataloader)\n",
    "    loss_ema = None\n",
    "    for x, cond in pbar:\n",
    "        optim.zero_grad()\n",
    "        x = x.to(device)\n",
    "        cond = cond.to(device)\n",
    "\n",
    "        # discritize x to N bins\n",
    "        x = (x * (N - 1)).round().long().clamp(0, N - 1)\n",
    "        loss, info = d3pm(x, cond)\n",
    "\n",
    "        loss.backward()\n",
    "        norm = torch.nn.utils.clip_grad_norm_(d3pm.x0_model.parameters(), 0.1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            param_norm = sum([torch.norm(p) for p in d3pm.x0_model.parameters()])\n",
    "\n",
    "        if loss_ema is None:\n",
    "            loss_ema = loss.item()\n",
    "        else:\n",
    "            loss_ema = 0.99 * loss_ema + 0.01 * loss.item()\n",
    "        pbar.set_description(\n",
    "            f\"loss: {loss_ema:.4f}, norm: {norm:.4f}, param_norm: {param_norm:.4f}, vb_loss: {info['vb_loss']:.4f}, ce_loss: {info['ce_loss']:.4f}\"\n",
    "        )\n",
    "        optim.step()\n",
    "        global_step += 1\n",
    "\n",
    "        if global_step % 300 == 1:\n",
    "            d3pm.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                cond = torch.arange(0, 4).to(device) % 10\n",
    "                init_noise = torch.randint(0, N, (4, 1, 32, 32)).to(device)\n",
    "\n",
    "                images = d3pm.sample_with_image_sequence(\n",
    "                    init_noise, cond, stride=40\n",
    "                )\n",
    "                # image sequences to gif\n",
    "                gif = []\n",
    "                for image in images:\n",
    "                    x_as_image = make_grid(image.float() / (N - 1), nrow=2)\n",
    "                    img = x_as_image.permute(1, 2, 0).cpu().numpy()\n",
    "                    img = (img * 255).astype(np.uint8)\n",
    "                    gif.append(Image.fromarray(img))\n",
    "\n",
    "                gif[0].save(\n",
    "                    f\"{dir_}/sample_{global_step}.gif\",\n",
    "                    save_all=True,\n",
    "                    append_images=gif[1:],\n",
    "                    duration=100,\n",
    "                    loop=0,\n",
    "                )\n",
    "\n",
    "                last_img = gif[-1]\n",
    "                last_img.save(f\"{dir_}/sample_{global_step}_last.png\")\n",
    "\n",
    "            d3pm.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89a266cd-b3e3-4560-a053-7f4407e8b32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70609b4f-cb6c-4585-aec2-5210204aaf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the end of your training loop\n",
    "checkpoint = {\n",
    "    'epoch': i,\n",
    "    'model_state_dict': d3pm.x0_model.state_dict(),\n",
    "    'optimizer_state_dict': optim.state_dict(),\n",
    "    'loss': loss_ema,\n",
    "}\n",
    "torch.save(checkpoint, 'd3pm_checkpoint_ising_1500.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19138684-d607-45cd-881d-00ee3a65f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_noise.shape, cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a526e-354f-4554-aa89-8b773f37809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d3pm.eval()\n",
    "\n",
    "\n",
    "cond = torch.arange(5, 9).cuda() % 10\n",
    "init_noise = torch.randint(0, N, (4, 1, 32, 32)).cuda()\n",
    "\n",
    "images = d3pm.sample_with_image_sequence(\n",
    "    init_noise, cond, stride=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b95516bb-3dcc-41bb-a06d-85fce075bd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6, 7, 8], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5b78c6c-2edc-480a-8802-d75bf35f05d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e031c272-8648-4552-9698-59e9f33e8af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7e24632ac950>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[-1].cpu().numpy()[2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4422de47-66fa-40dc-83c0-cc315812564d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
